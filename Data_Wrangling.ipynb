{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "\n",
    "Data Wrangling can be defined as the process to:\n",
    "* gather\n",
    "* assess\n",
    "* clean\n",
    "data in support of data analytics tasks.\n",
    "\n",
    "This notebook contains the code to extract data related to Master Swim Performances and save it in a local format that supports Data Exploration activities.\n",
    "\n",
    "## Supported Data Sources\n",
    "\n",
    "Currently data is only extracted from the Canadian swimming site that collects the results for Masters Swimmers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "When I created the meet list for a complete season, I found that some meets don't have results posted\n",
    "\n",
    "Right now, my code assumes that results will exist.  This will need to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import randint\n",
    "import logging\n",
    "import utilities as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the logger and initially set the logging level to debug\n",
    "# since I am using a notebook, I am not going to capture the log in a file\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canadian Master Swimming Results Collection \n",
    "\n",
    "Starting with the information I know how to access from personal experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather - www.swimming.ca\n",
    "The following code will scrape the available data from the www.swimming.ca website for Masters Swimmers. The code is based on the website structure that exists during the time period Aug - Oct 2020.\n",
    "\n",
    "The website has a layered approach to finding results.\n",
    "1. Navigate to the page that has a list of meet-results\n",
    "2. Filter the list of meet results by **Season**, **Province**, **Month**\n",
    "3. Select the meet of interest in the filtered list\n",
    "4. At this point it is possible to see all the results for each club that participated, or the results by event.  I will be collecting all the results by participating club.\n",
    "\n",
    "I did contact Swim Canada to see if there was an API that would allow me to use an approach other than web scraping to get the results, but so far they have not been able to support my request.\n",
    "\n",
    "For the parameters **Seasion**, **Province** and **Month**, there are few points to note:\n",
    "* Season - the swim season in Canada is split over 2 calendar years and runs Sep to Aug.  So the swim season 2019/2020 will be the period 1 Sep 2019 to 31 Aug 2020.  The value passed to the **Season** parameter is the last 2 numbers in the second part of the season identifier.  So to access swim meets from Nov 2019, the season parameter will be 20 ('season'='20')\n",
    "* Month - the month must be specified as a number from 1 to 12.  It is not possible to have all the months in a single season being available at one time\n",
    "* Province - It is possible to filter by province/territory or use all provinces. To access an individual province/territory, the provinces/territories are numbered from 1 to 11 in alphabetical order.  So to get only Alberta, 'province'='1' and to get Yukon, 'province'='11'.  The supported Territories are Northwest Territories and Yukon.  For all provinces, no number is provided to province (province = '')\n",
    "\n",
    "Since I am only interested in Masters results, when looking at the meet list, I will look for MEET TYPE  of Masters.  This will miss some swimmers that compete in non-Masters meets as an Open Master.  I plan to come back and find these results after collecting the Masters Meets\n",
    "\n",
    "The only URL specified in my code is the URL associated with step 1 above, navigating to the meet-results page.  The subsequent URLs will be recovered from the information available when the various filters are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of interest\n",
    "url_meetlist ='https://www.swimming.ca/en/events-results/meet-results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the logging level\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Meet Info\n",
    "The next section of code is used to retrieve meet information and write the results to a csv.  One csv per season\n",
    "\n",
    "### Seasons Processed\n",
    "To see what seasons have been processed, look at the csv's in the same file folder as this notebook.  Best effort list as I process a season:\n",
    "* 2019-2020\n",
    "* 2018-2019\n",
    "* 2017-2018\n",
    "* 2016-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each season:\n",
    "\n",
    "* update the season value and csv name in the dictionary\n",
    "* change the returned list to a datafram\n",
    "* write the dataframe to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dict = {}\n",
    "season_dict['season'] = '18'\n",
    "season_dict['meet_file'] = 'meets_2017_2018.csv'\n",
    "season_dict['club_file'] = 'clubs_2017_2018.csv'\n",
    "season_dict['swimmers_file'] = 'swimmers_2017_2018.csv'\n",
    "season_dict['race_file'] = 'races_2017_2018.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get meet list\n",
    "def getMeetList(season, month, base_url):\n",
    "    #create param list for the URL\n",
    "    call_params = {'season': season, 'province':'', 'month': month}\n",
    "    \n",
    "    #get the page after a random delay\n",
    "    #I think the crawl delay is 10 seconds, so while it will take longer,\n",
    "    #I will set a random delay of 10-14 seconds\n",
    "    sleepTime = randint(10,14)\n",
    "    logging.debug(\"sleep time is %i seconds\", sleepTime)\n",
    "    time.sleep(sleepTime)\n",
    "    response=requests.get(base_url, params=call_params)\n",
    "    logging.debug('%s', response.url)\n",
    "    \n",
    "    #parse the page and create the list\n",
    "    #use Beautiful Soup to parse the returned page\n",
    "    meetList_resp = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    rtnList = []\n",
    "    for item in meetList_resp.find_all('tr'):\n",
    "        if item.contents[5].contents[0] == \"Masters\":\n",
    "            ## need to handle the case where there was a meet, but there are no results\n",
    "            \n",
    "            temp_dict = {}\n",
    "            try:\n",
    "                temp_dict['meet_date'] = item.contents[0].contents[0].contents[0]\n",
    "            except:\n",
    "                temp_dict['meet_date'] = None\n",
    "                \n",
    "            try:    \n",
    "                temp_dict['meet_url'] = item.contents[1].a.attrs['href']\n",
    "            except:\n",
    "                temp_dict['meet_url'] = None\n",
    "                \n",
    "            try:    \n",
    "                temp_dict['meet_prov'] = item.contents[2].contents[0]\n",
    "            except:\n",
    "                temp_dict['meet_prov'] = None\n",
    "                \n",
    "            try:\n",
    "                temp_dict['meet_host'] = item.contents[3].contents[0].contents[0]\n",
    "            except:\n",
    "                temp_dict['meet_host'] = None\n",
    "                \n",
    "            try:\n",
    "                temp_dict['meet_course'] = item.contents[4].contents[0]\n",
    "            except:\n",
    "                temp_dict['meet_course'] = None\n",
    "                \n",
    "            try:\n",
    "                temp_dict['meet_type'] = item.contents[5].contents[0]\n",
    "            except:\n",
    "                temp_dict['meet_type'] = None\n",
    "                \n",
    "            try:\n",
    "                temp_dict['meet_status'] = item.contents[6].contents[0]\n",
    "            except:\n",
    "                temp_dict['meet_status'] = None\n",
    "                \n",
    "            rtnList.append(temp_dict)\n",
    "    \n",
    "    logging.debug(\"Number of meets: %i\", len(rtnList))\n",
    "    #return the list of meets\n",
    "    return rtnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeetListFn = []\n",
    "\n",
    "#get the meet list for a season\n",
    "monthList = ['9', '10', '11', '12', '1', '2', '3', '4', '5', '6', '7', '8']\n",
    "for mon in monthList:\n",
    "    logging.info(\"month being processed %s\", mon)\n",
    "    tempList = getMeetList(season_dict['season'], mon, url_meetlist)\n",
    "    for item in tempList:\n",
    "        MeetListFn.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MeetListFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe and write the dataframe to a csv\n",
    "df = pd.DataFrame(MeetListFn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(season_dict['meet_file'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get teams participating in meet info\n",
    "\n",
    "Next section will get the team lists for each meet and write the results to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the meet list file\n",
    "#df_meet = pd.read_csv('meets_2018_2019.csv')\n",
    "df_meet = pd.read_csv(season_dict['meet_file'])\n",
    "df_meet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of the meet urls\n",
    "meetURLS = df_meet['meet_url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the logging level\n",
    "#logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTeamList(meet_url):\n",
    "    \n",
    "    logging.debug(meet_url)\n",
    "    sleepTime = randint(10,14)\n",
    "    logging.debug(\"sleep time is %i seconds\", sleepTime)\n",
    "    time.sleep(sleepTime)\n",
    "    response=requests.get(meet_url)\n",
    "    logging.debug('%s', response.url)\n",
    "        \n",
    "    #parse the swim club list page\n",
    "    #use Beautiful Soup to parse the returned page\n",
    "    clubList_resp = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    rtnList = []\n",
    "    for item in clubList_resp.find_all('option'):\n",
    "        temp_dict = {}\n",
    "        if \"Events\" in item.contents[0]:\n",
    "            logging.debug(\"Did I get here?\")\n",
    "            break\n",
    "        elif \"Participants\" not in item.contents[0]:\n",
    "            try:\n",
    "                temp_dict['club_res_url'] = item.attrs['data-href']\n",
    "            except:\n",
    "                temp_dict['club_res_url'] = None\n",
    "            try:\n",
    "                temp_dict['club_number'] = item.attrs['value']\n",
    "            except:\n",
    "                temp_dict['club_number'] = None\n",
    "            try:\n",
    "                temp_dict['club_name'] = item.contents[0]\n",
    "            except:\n",
    "                temp_dict['club_name'] = None\n",
    "            rtnList.append(temp_dict)\n",
    "\n",
    "    return rtnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubListFn = []\n",
    "\n",
    "for meet in meetURLS:\n",
    "    logging.info(\"meet URL %s\", meet)\n",
    "    tempList = getTeamList(meet)\n",
    "    for item in tempList:\n",
    "        clubListFn.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe and write the dataframe to a csv\n",
    "club_df = pd.DataFrame(clubListFn)\n",
    "club_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#club_df.to_csv('clubs_2018_2019.csv', index=False)\n",
    "club_df.to_csv(season_dict['club_file'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get swimmer and race info\n",
    "\n",
    "The next section will get the results for meet and save the information to two files.  One will contain the information on the swimmer and one will contain the informaiton on the races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'season': '18',\n",
       " 'meet_file': 'meets_2017_2018.csv',\n",
       " 'club_file': 'clubs_2017_2018.csv',\n",
       " 'swimmers_file': 'swimmers_2017_2018.csv',\n",
       " 'race_file': 'races_2017_2018.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the csv containing the club links\n",
    "swims_df = pd.read_csv(season_dict['club_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swims_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club_name</th>\n",
       "      <th>club_number</th>\n",
       "      <th>club_res_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La Vague de Brossard</td>\n",
       "      <td>73992.0</td>\n",
       "      <td>https://www.swimming.ca/en/meet/604494/?factio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McGill Masters</td>\n",
       "      <td>76063.0</td>\n",
       "      <td>https://www.swimming.ca/en/meet/604494/?factio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E.N. Longueuil</td>\n",
       "      <td>72351.0</td>\n",
       "      <td>https://www.swimming.ca/en/meet/604494/?factio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maitres A Contre-Courant</td>\n",
       "      <td>74019.0</td>\n",
       "      <td>https://www.swimming.ca/en/meet/604494/?factio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Club Aquatique Montreal</td>\n",
       "      <td>72346.0</td>\n",
       "      <td>https://www.swimming.ca/en/meet/604494/?factio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  club_name  club_number  \\\n",
       "0      La Vague de Brossard      73992.0   \n",
       "1            McGill Masters      76063.0   \n",
       "2            E.N. Longueuil      72351.0   \n",
       "3  Maitres A Contre-Courant      74019.0   \n",
       "4   Club Aquatique Montreal      72346.0   \n",
       "\n",
       "                                        club_res_url  \n",
       "0  https://www.swimming.ca/en/meet/604494/?factio...  \n",
       "1  https://www.swimming.ca/en/meet/604494/?factio...  \n",
       "2  https://www.swimming.ca/en/meet/604494/?factio...  \n",
       "3  https://www.swimming.ca/en/meet/604494/?factio...  \n",
       "4  https://www.swimming.ca/en/meet/604494/?factio...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swims_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(swims_df['club_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of urls for the results from each club\n",
    "clubURLS = swims_df['club_res_url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.swimming.ca/en/meet/604494/?faction=73992'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clubURLS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:https://www.swimming.ca/en/meet/604494/?faction=73992\n",
      "DEBUG:root:sleep time is 10 seconds\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.swimming.ca:443\n",
      "DEBUG:urllib3.connectionpool:https://www.swimming.ca:443 \"GET /en/meet/604494/?faction=73992 HTTP/1.1\" 200 None\n",
      "DEBUG:root:https://www.swimming.ca/en/meet/604494/?faction=73992\n",
      "DEBUG:root:number of tables 5\n",
      "DEBUG:root:on table 0\n",
      "DEBUG:root:first row of table, ignore\n",
      "DEBUG:root:on table 1\n",
      "DEBUG:root:first row of table, ignore\n",
      "DEBUG:root:on table 2\n",
      "DEBUG:root:first row of table, ignore\n"
     ]
    }
   ],
   "source": [
    "#test my utils file\n",
    "tmp_sw, tmp_rc = util.getRaceResults(clubURLS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sw_url': 'https://www.swimming.ca/en/swimmer/4209372/',\n",
       " 'sw_id': '4209372',\n",
       " 'sw_name': 'Aviles, Carlos',\n",
       " 'sw_yob': '1975',\n",
       " 'sw_gender': 'male'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_sw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rc_dist_stroke': '50m Freestyle',\n",
       " 'rc_round': 'Final',\n",
       " 'rc_time': '29.04',\n",
       " 'rc_course': '25m',\n",
       " 'sw_id': '4209372',\n",
       " 'sw_yob': '1975',\n",
       " 'sw_gender': 'male'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_rc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clubURLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3_url = clubList[0]['club_res_url']\n",
    "r3 = requests.get(r3_url)\n",
    "temp_r3 = BeautifulSoup(r3.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table = temp_r3.find_all(\"table\")\n",
    "len(temp_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: use this method with the previously define method rather than having the code repeated multiple times\n",
    "def scrapePage(url):\n",
    "    #get the page with the results for the club\n",
    "    logging.debug(url)\n",
    "    sleepTime = randint(10,14)\n",
    "    logging.debug(\"sleep time is %i seconds\", sleepTime)\n",
    "    time.sleep(sleepTime)\n",
    "    response=requests.get(url)\n",
    "    logging.debug('%s', response.url)\n",
    "    \n",
    "    #use Beautiful Soup to parse the returned page\n",
    "    resp = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    #return the page\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSwimmerInfo(tableRow):\n",
    "    \n",
    "    #create return dictionary\n",
    "    sw_dict = {}\n",
    "    \n",
    "    #parse the row\n",
    "    try:\n",
    "        sw_dict['sw_url'] = tableRow.find('a').attrs['href']\n",
    "    except:\n",
    "        sw_dict['sw_url'] = None \n",
    "    try:\n",
    "        #sw_id = tableRow.find('a').attrs['href'].split('/')[5]\n",
    "        sw_dict['sw_id'] = tableRow.find('a').attrs['href'].split('/')[5]\n",
    "    except:\n",
    "        sw_dict['sw_id'] = None\n",
    "    try:\n",
    "        sw_dict['sw_name'] = tableRow.find('a').contents[0]\n",
    "    except:     \n",
    "        sw_dict['sw_name'] = None\n",
    "    try:\n",
    "        sw_dict['sw_yob'] = tableRow.find('th').contents[1][3:7]\n",
    "    except:    \n",
    "        sw_dict['sw_yob'] = None\n",
    "        \n",
    "    #return the dictionary\n",
    "    return sw_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing, I am going to get 2 pages - one with relays and one without to make sure I can handle either\n",
    "url_relays = 'https://www.swimming.ca/en/meet/598224/?faction=73928'\n",
    "url_no_relays = 'https://www.swimming.ca/en/meet/597428/?faction=74044'\n",
    "relay_pg = scrapePage(url_relays)\n",
    "no_relay_pg = scrapePage(url_no_relays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRaceInfo(tableRow):\n",
    "    \n",
    "    #create return dictionary\n",
    "    rc_dict = {}\n",
    "    \n",
    "    #rc_dict['sw_id'] = sw_id\n",
    "    #rc_dict['sw_yob'] = sw_yob\n",
    "    #try:\n",
    "    #    rc_dict['sw_gender'] = tableRow.contents[0].find('a').attrs['data-query-gender']\n",
    "    #except:\n",
    "    #    rc_dict['sw_gender'] = None\n",
    "    try:\n",
    "        rc_dict['rc_dist_stroke'] = tableRow.contents[0].find('span').find('a').contents[0]\n",
    "    except:\n",
    "        rc_dict['rc_dist_stroke'] = None\n",
    "    try:\n",
    "        rc_dict['rc_round'] = tableRow.contents[1].contents[0]\n",
    "    except:\n",
    "        rc_dict['rc_round'] = None\n",
    "    try:\n",
    "        rc_dict['rc_time'] = tableRow.contents[3].contents[0]\n",
    "    except:\n",
    "        rc_dict['rc_time'] = None\n",
    "    try:\n",
    "        rc_dict['rc_course'] = tableRow.contents[4].find('abbr').contents[0]\n",
    "    except:\n",
    "        rc_dict['rc_course'] = None\n",
    "    \n",
    "    #print(rc_dict)\n",
    "    return rc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remember to change this back to use the URL as input\n",
    "def getRaceResults(club_url):\n",
    "#def getRaceResults(raceList_resp):\n",
    "    \n",
    "    ##### Remember to uncomment this to scrape the page\n",
    "    #get the page with the results for the club\n",
    "    raceList_resp = scrapePage(club_url)\n",
    "\n",
    "    #create a list of tables on the page\n",
    "    temp_table = raceList_resp.find_all('table')\n",
    "    logging.debug(\"number of tables %i\", len(temp_table))\n",
    "    \n",
    "    #create a gender table to use based on which table is being parsed\n",
    "    gender_dict = {0:\"male\", 1:\"female\", 2:\"relay\"}\n",
    "    \n",
    "    #create lists to hold swimmer and race info\n",
    "    swimmer_list = []\n",
    "    race_list = []\n",
    "    \n",
    "    #if 3 or more tables, there are results on the page\n",
    "    if len(temp_table) < 3:\n",
    "        logging.info(\"no results on the page\")\n",
    "        #add code to put all nulls in the return value\n",
    "    else:\n",
    "        for tt in range(len(temp_table)-2):\n",
    "            logging.debug(\"on table %i\", tt)\n",
    "            #set a flag for the first row, want to ignore it\n",
    "            firstRow = True\n",
    "            \n",
    "            #get the gender based on which table is being parsed\n",
    "            sw_gender = gender_dict[tt]\n",
    "            \n",
    "            #create variables to hold the last swimmer id and yob\n",
    "            sw_id = None\n",
    "            sw_yob = None\n",
    "            \n",
    "            #loop through each row in the table\n",
    "            for item in temp_table[tt].find_all('tr'):\n",
    "                temp_sw_dict = {}\n",
    "                temp_rc_dict = {}\n",
    "                if firstRow == True:\n",
    "                    logging.debug(\"first row of table, ignore\")\n",
    "                    firstRow = False\n",
    "                elif item.has_attr('class'):\n",
    "                    #parse the swimmer information\n",
    "                    temp_sw_dict = parseSwimmerInfo(item)\n",
    "                    \n",
    "                    #add the gender\n",
    "                    try:\n",
    "                        temp_sw_dict['sw_gender'] = sw_gender\n",
    "                    except:\n",
    "                        temp_sw_dict['sw_gender'] = None\n",
    "                        \n",
    "                    #make the swimmer id and yob available\n",
    "                    sw_id = temp_sw_dict['sw_id']\n",
    "                    sw_yob = temp_sw_dict['sw_yob']\n",
    "                        \n",
    "                    #append to the return list\n",
    "                    swimmer_list.append(temp_sw_dict)\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    #parse the race information\n",
    "                    temp_rc_dict = parseRaceInfo(item)\n",
    "                    \n",
    "                    #add the swimmer id, yob, gender\n",
    "                    temp_rc_dict['sw_id'] = sw_id\n",
    "                    temp_rc_dict['sw_yob'] = sw_yob\n",
    "                    temp_rc_dict['sw_gender'] = sw_gender\n",
    "                    \n",
    "                    #append to the return list\n",
    "                    race_list.append(temp_rc_dict)\n",
    "                    \n",
    "                #else:\n",
    "                #    logging.debug(\"expect no information in this row\")\n",
    "                #count += 1\n",
    "    return swimmer_list, race_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1, test2 = getRaceResults('https://www.swimming.ca/en/meet/618134/?faction=74044')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_list = []\n",
    "rc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in clubURLS:\n",
    "    try:\n",
    "        if \"https\" in item:\n",
    "            tmp_sw_list, tmp_rc_list = getRaceResults(item)\n",
    "            sw_list += tmp_sw_list\n",
    "            rc_list += tmp_rc_list\n",
    "    except:\n",
    "        print(item, \"is not a valid url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubURLS[86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clubURLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clubURLS[87:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubURLS[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_clubURLS = clubURLS[86:]\n",
    "trim_clubURLS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_clubURLS[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in trim_clubURLS[0:4]:\n",
    "    try:\n",
    "        if \"https\" in item:\n",
    "            print(item, \" is valid url\")\n",
    "    except:\n",
    "        print(item, \" is not a valid url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in trim_clubURLS:\n",
    "    try:\n",
    "        if \"https\" in item:\n",
    "            tmp_sw_list, tmp_rc_list = getRaceResults(item)\n",
    "            sw_list += tmp_sw_list\n",
    "            rc_list += tmp_rc_list\n",
    "    except:\n",
    "        print(item, \"is not a valid url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swim_df = pd.DataFrame(sw_list)\n",
    "swim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swim_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = pd.DataFrame(rc_list)\n",
    "race_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swim_df.to_csv(season_dict['swimmers_file'], index=False)\n",
    "race_df.to_csv(season_dict['race_file'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sw_list, tmp_rc_list = getRaceResults(relay_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp_sw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sw_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp_rc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_rc_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_list += tmp_sw_list\n",
    "rc_list += tmp_rc_list\n",
    "\n",
    "print(\"sw_list\", len(sw_list), \"rc_list\", len(rc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sw_list, tmp_rc_list = getRaceResults(no_relay_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp_sw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp_rc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_list += tmp_sw_list\n",
    "rc_list += tmp_rc_list\n",
    "\n",
    "print(\"sw_list\", len(sw_list), \"rc_list\", len(rc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess - www.swimming.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean - www.swimming.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Code\n",
    "\n",
    "While creating the final functions, I used the following code to explore the webpages to set up the parsing correctly\n",
    "\n",
    "I don't want to loose it, but it should not be run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Structure of html pages\n",
    "In order to recover the information of interest, the way the information is presented on the various html pages needs to be understood.\n",
    "\n",
    "Once I know how to capture the data of interest, I will create functions to iterate through diffferent seasons, months and meets.\n",
    "\n",
    "The information I am interested in can be grouped into 3 categories.\n",
    "\n",
    "**Swimmer Information**\n",
    "* sw_id_num - unique swimmer id number\n",
    "* sw_name - swimmers name\n",
    "* sw_yob - swimmers year of birth\n",
    "\n",
    "Note that swimmers age is determined by the age on Dec 31st of the year in which the competition happened.\n",
    "\n",
    "**Meet Information**\n",
    "\n",
    "* mt_id_num - unique meet id number\n",
    "* mt_name - meet name\n",
    "* mt_date - first day of meet\n",
    "* mt_duration - number of days the swim meet lasted\n",
    "* mt_pool_name - name of the pool\n",
    "* mt_pool_address - address of the pool\n",
    "* mt_sc_lc - indication if meet was a long course or short course meet\n",
    "\n",
    "**Race Information**\n",
    "* rc_dist - distance of race - eg 25m, 100m, 400m\n",
    "* rc_stroke - stroke of race - freestyle, backstroke, butterfly, breaststroke, IM\n",
    "* rc_time - time it took the swimmer to complete the distance\n",
    "* rc_round - heat, final, split of longer swim or part of relay\n",
    "* sw_id_num - unique swimmer id\n",
    "* mt_id_num - unique meet id\n",
    "\n",
    "I am also confident that at some point I will want club information, but at this point I'm not sure what I would do with it.\n",
    "\n",
    "I also have not decided the best way to store the information I scrape.  Initially, I will put it in 3 different csv's, but would like to explore a graph database.  I have not used them before and would like to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with the 2019/2020 season, noting that the season came to an abrupt end in March 2020 because of Covid19\n",
    "# using November since I know there is a masters meet in Nov 2019\n",
    "call_params = {'season':'20', 'province':'', 'month':'11'}\n",
    "#response=requests.get('https://www.swimming.ca/en/events-results/meet-results/', params={'season':'20', 'province':'', 'month':'11'})\n",
    "response=requests.get('https://www.swimming.ca/en/events-results/meet-results/', params=call_params)\n",
    "#sanity check that my parameter specification worked as expected\n",
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Beautiful Soup to parse the returned page\n",
    "meetList_resp = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetList_resp.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the masters swim meets in the response text\n",
    "meetList = []\n",
    "for item in meetList_resp.find_all('tr'):\n",
    "    if item.contents[5].contents[0] == \"Masters\":\n",
    "        temp_dict = {}\n",
    "        temp_dict['meet_date'] = item.contents[0].contents[0].contents[0]\n",
    "        temp_dict['meet_url'] = item.contents[1].a.attrs['href']\n",
    "        temp_dict['meet_prov'] = item.contents[2].contents[0]\n",
    "        temp_dict['meet_host'] = item.contents[3].contents[0].contents[0]\n",
    "        temp_dict['meet_course'] = item.contents[4].contents[0]\n",
    "        temp_dict['meet_type'] = item.contents[5].contents[0]\n",
    "        meetList.append(temp_dict)\n",
    "        ##used for debug/development\n",
    "        #print(item.contents[0].contents[0].contents[0])\n",
    "        #print(item.contents[1].a.attrs['href'])\n",
    "        #print(item.contents[2].contents[0])\n",
    "        #print(item.contents[3].contents[0].contents[0])\n",
    "        #print(item.contents[4].contents[0])\n",
    "        #print(item.contents[5].contents[0])\n",
    "print(\"number of masters meets\", len(meetList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 8 masters meets were held in Canada in Nov 2019.\n",
    "\n",
    "Now use the meet_url to get the results for that meet.  The use Beautiful Soup to parse the returned page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_url = meetList[0]['meet_url']\n",
    "r2 = requests.get(r2_url)\n",
    "temp_r2 = BeautifulSoup(r2.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My next step was to create a list of clubs that participated. I looked through the html on the page and determined the information I was interested in was held in 'option' tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubList = []\n",
    "for item in temp_r2.find_all('option'):\n",
    "    #print(item.contents[0])\n",
    "    temp_dict = {}\n",
    "    if \"Events\" in item.contents[0]:\n",
    "        #print(item)\n",
    "        break\n",
    "    elif \"Participants\" not in item.contents[0]:\n",
    "        temp_dict['club_res_url'] = item.attrs['data-href']\n",
    "        temp_dict['club_number'] = item.attrs['value']\n",
    "        temp_dict['club_name'] = item.contents[0]\n",
    "        clubList.append(temp_dict)\n",
    "        ## used for dev/debug\n",
    "        #print(item.attrs['data-href'])\n",
    "        #print(item.attrs['value'])\n",
    "        #print(item.contents[0])\n",
    "        \n",
    "print(\"number of clubs in the meet\", len(clubList))\n",
    "print(\"information about each club\") \n",
    "clubList[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to get the club results and retrieve the information about each swimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3_url = clubList[0]['club_res_url']\n",
    "r3 = requests.get(r3_url)\n",
    "temp_r3 = BeautifulSoup(r3.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the HTML for the per club results page, the results of interest seem to be in the first 4 tables:\n",
    "* table 0 - men's results\n",
    "* table 1 - women's results\n",
    "* table 2 - relay results\n",
    "* table 3 - meet resource info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table = temp_r3.find_all(\"table\")\n",
    "len(temp_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the results for the men's table\n",
    "count = 0\n",
    "swimmer_list = []\n",
    "race_list = []\n",
    "for item in temp_table[0].find_all('tr'):\n",
    "    temp_sw_dict = {}\n",
    "    temp_rc_dict = {}\n",
    "    if item.has_attr('class'):\n",
    "        print(\"new swimmer!!\")\n",
    "        #print(\"row count\", count, \"length of info\", len(item), \"contents\", item)\n",
    "        #print(\"swimmer url\", item.find('a').attrs['href'])\n",
    "        #print(\"swimmer id\", item.find('a').attrs['href'].split('/')[5])\n",
    "        #print(\"swimmer name\", item.find('a').contents[0])\n",
    "        #print(\"swimmer YOB\", item.find('th').contents[1][3:7])\n",
    "        # need swim id for both the swimmer and the race dictionary\n",
    "        sw_id = item.find('a').attrs['href'].split('/')[5]\n",
    "        sw_yob = item.find('th').contents[1][3:7]\n",
    "        temp_sw_dict['sw_url'] = item.find('a').attrs['href']\n",
    "        temp_sw_dict['sw_id'] = sw_id\n",
    "        temp_sw_dict['sw_name'] = item.find('a').contents[0]\n",
    "        temp_sw_dict['sw_yob'] = sw_yob\n",
    "        swimmer_list.append(temp_sw_dict)\n",
    "    #print(count)\n",
    "    #if item.children[0].has_attr('class'):\n",
    "    #    print(\"race time and dist available\")\n",
    "    #    print(item.children[0])\n",
    "    elif count != 0:\n",
    "        #print(\"row count\", count, len(item.contents))\n",
    "        #for subItem in item:\n",
    "        #    print(len(subItem), subItem.string)\n",
    "        #print(\"gender\", item.contents[0].find('a').attrs['data-query-gender'])\n",
    "        #print(\"race distance and stroke\", item.contents[0])\n",
    "        #print(\"race distance and stroke\", item.contents[0].find('span').find('a').contents[0])\n",
    "        #print(\"race round\", item.contents[1].contents[0])\n",
    "        #print(\"race time\", item.contents[3].contents[0])\n",
    "        #get the gender for both swim and race dict\n",
    "        sw_gender = item.contents[0].find('a').attrs['data-query-gender']\n",
    "        temp_rc_dict['sw_id'] = sw_id\n",
    "        temp_rc_dict['sw_yob'] = sw_yob\n",
    "        temp_rc_dict['sw_gender'] = sw_gender\n",
    "        #temp_sw_dict['sw_gender'] = sw_gender\n",
    "        temp_rc_dict['rc_dist_stroke'] = item.contents[0].find('span').find('a').contents[0]\n",
    "        temp_rc_dict['rc_round'] = item.contents[1].contents[0]\n",
    "        temp_rc_dict['rc_time'] = item.contents[3].contents[0]\n",
    "        race_list.append(temp_rc_dict)\n",
    "    else:\n",
    "        print(\"row count\", count)\n",
    "    \n",
    "    #append the temp dict to the lists\n",
    "    #swimmer_list.append(temp_sw_dict)\n",
    "    #race_list.append(temp_rc_dict)\n",
    "    count += 1\n",
    "    # just print out some to see the pattern\n",
    "    #if count == 11:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swimmer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
